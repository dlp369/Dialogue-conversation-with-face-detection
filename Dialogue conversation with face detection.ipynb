{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38bf0d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install facenet-pytorch opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c415a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Loading the MTCNN (Multi-task Cascaded Convolutional Networks) face detection model\n",
    "mtcnn = MTCNN(keep_all=True)\n",
    "\n",
    "# Loading the video\n",
    "video_capture = cv2.VideoCapture('Random Conversation Between Two Friends.mp4')\n",
    "\n",
    "# Getting the video properties\n",
    "frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Creating a VideoWriter object to save the processed video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "detection_output = cv2.VideoWriter('Face_detection_output.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "objects = []\n",
    "\n",
    "while True:\n",
    "    # Reading each frame from the video\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Converting the frame to RGB (MTCNN requires RGB images)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detecting faces in the frame\n",
    "    boxes, _ = mtcnn.detect(rgb_frame)\n",
    "    objects.append(boxes)\n",
    "\n",
    "    # Drawing rectangles around the detected faces\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            x, y, w, h = map(int, box)\n",
    "            cv2.rectangle(frame, (x, y), (w, h), (255, 0, 0), 2)\n",
    "    \n",
    "    # Writing the frame to the output video\n",
    "    detection_output.write(frame)\n",
    "\n",
    "    # Displaying the frame with the detected faces\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Breaking the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Releasing the video capture object, the output video object, and closing all windows\n",
    "video_capture.release()\n",
    "detection_output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2eb4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list to store no of faces detected in each frame\n",
    "no_of_object=[]\n",
    "\n",
    "for i in objects:\n",
    "    try:\n",
    "        no_of_object.append(len(i))\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee01a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculating total number of speakers\n",
    "no_of_speaker = np.round(np.mean(no_of_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49d342fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import assemblyai as aai\n",
    "\n",
    "# API key\n",
    "aai.settings.api_key = \"a7dd5ffaa8f348a1a82ecbe74fbe0732\"\n",
    "\n",
    "# Audio path\n",
    "audio_url = 'temp.wav'\n",
    "\n",
    "transcriber = aai.Transcriber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62d78ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = aai.TranscriptionConfig(speaker_labels = True, speakers_expected = no_of_speaker)\n",
    "\n",
    "transcript = transcriber.transcribe(audio_url, config)\n",
    "\n",
    "with open('Subtitles.txt','a') as f:\n",
    "    f.write(transcript.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c8a6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = []\n",
    "end_time = []\n",
    "speaker = []\n",
    "text = []\n",
    "\n",
    "for utterance in transcript.utterances:\n",
    "    with open('Speaker Diarization.txt','a') as file:\n",
    "        file.write(f\"Speaker {utterance.speaker}: {utterance.text}\\n\")\n",
    "        file.write(f\"Start time: {utterance.start/1000} | End time: {utterance.end/1000}\\n\\n\")\n",
    "    \n",
    "    start_time.append(utterance.start)\n",
    "    end_time.append(utterance.end)\n",
    "    speaker.append(utterance.speaker)\n",
    "    text.append(utterance.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f31ccad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame({'Speaker':speaker,'Text':text,'Start time[ms]':start_time,'End time[ms]':end_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e4d06fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "# Loading the audio file\n",
    "audio = AudioFileClip('temp.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0757c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for i in df['Speaker'].unique():\n",
    "    directory = f'C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_{i}'\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3bfc8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in speaker_A_segment_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_B_segment_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_A_segment_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_B_segment_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_A_segment_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_B_segment_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_A_segment_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_B_segment_7.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_A_segment_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_B_segment_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_A_segment_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_B_segment_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_A_segment_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_B_segment_13.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_A_segment_14.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_B_segment_15.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_A_segment_16.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_B_segment_17.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Iterating over speaker labels and segment the audio\n",
    "for index, row in df.iterrows():\n",
    "    start_time = row['Start time[ms]']/1000   # Start time in seconds\n",
    "    end_time = row['End time[ms]']/1000      # End time in seconds\n",
    "    speaker = row['Speaker']\n",
    "\n",
    "    # Extracting the segment\n",
    "    segment = audio.subclip(start_time, end_time)\n",
    "\n",
    "    # Exporting the segment to a file \n",
    "    for i in df['Speaker'].unique():\n",
    "        if speaker == i:\n",
    "            os.chdir(f'C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_{i}')\n",
    "            segment.write_audiofile(f\"speaker_{speaker}_segment_{index}.wav\", codec='pcm_s16le')\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df7433e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in C:\\Users\\HOME\\DS\\0. PROJECTS\\Dialogue conversation with face detection\\speaker_A_joined_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in C:\\Users\\HOME\\DS\\0. PROJECTS\\Dialogue conversation with face detection\\speaker_B_joined_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import AudioFileClip, concatenate_audioclips\n",
    "import os\n",
    "\n",
    "for folder in os.listdir('C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker'):\n",
    "    count = 0\n",
    "    audio = dict()\n",
    "    # Load the audio files\n",
    "    for file in os.listdir(f'C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\{folder}'):\n",
    "        audio_count = AudioFileClip(os.path.join(f'C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\{folder}', file))\n",
    "        audio.update({count:audio_count})\n",
    "        count += 1\n",
    "    audio = audio.values()\n",
    "    # Concatenate the audio files\n",
    "    joined_audio = concatenate_audioclips(audio)\n",
    "    \n",
    "    # Export the joined audio to a new file\n",
    "    joined_audio.write_audiofile(f\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\{folder}_joined_audio.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6c61b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83c39609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in speaker_A_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in speaker_B_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import AudioFileClip, concatenate_audioclips\n",
    "\n",
    "# Load the audio files\n",
    "audio1 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_A\\\\speaker_A_segment_0.wav\")\n",
    "audio2 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_A\\\\speaker_A_segment_2.wav\")\n",
    "audio3 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_A\\\\speaker_A_segment_4.wav\")\n",
    "audio4 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_A\\\\speaker_A_segment_6.wav\")\n",
    "audio5 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_A\\\\speaker_A_segment_8.wav\")\n",
    "audio6 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_A\\\\speaker_A_segment_10.wav\")\n",
    "audio7 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_A\\\\speaker_A_segment_12.wav\")\n",
    "audio8 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_A\\\\speaker_A_segment_14.wav\")\n",
    "audio9 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_A\\\\speaker_A_segment_16.wav\")\n",
    "\n",
    "audio10 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_B\\\\speaker_B_segment_1.wav\")\n",
    "audio11 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_B\\\\speaker_B_segment_3.wav\")\n",
    "audio12 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_B\\\\speaker_B_segment_5.wav\")\n",
    "audio13 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_B\\\\speaker_B_segment_7.wav\")\n",
    "audio14 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_B\\\\speaker_B_segment_9.wav\")\n",
    "audio15 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_B\\\\speaker_B_segment_11.wav\")\n",
    "audio16 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_B\\\\speaker_B_segment_13.wav\")\n",
    "audio17 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_B\\\\speaker_B_segment_15.wav\")\n",
    "audio18 = AudioFileClip(\"C:\\\\Users\\\\HOME\\\\DS\\\\0. PROJECTS\\\\Dialogue conversation with face detection\\\\speaker\\\\speaker_B\\\\speaker_B_segment_17.wav\")\n",
    "\n",
    "# Concatenate the audio files\n",
    "joined_audio1 = concatenate_audioclips([audio1, audio2, audio3, audio4, audio5, audio6, audio7, audio8, audio9])\n",
    "joined_audio2 = concatenate_audioclips([audio10, audio11, audio12, audio13, audio14, audio15, audio16, audio17, audio18])\n",
    "\n",
    "# Export the joined audio to a new file\n",
    "joined_audio1.write_audiofile(\"speaker_A_audio.wav\")\n",
    "joined_audio2.write_audiofile(\"speaker_B_audio.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342ef72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
